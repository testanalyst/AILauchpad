{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOf0iM+pUfT5VjvnCBHUy4Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/testanalyst/AILaunchpad/blob/main/Assignment3_Day2_PromptEngineering_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzuZuX0aD7IN",
        "outputId": "b4cb94bb-c158-419a-e5be-e45f64f98668"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.5\n",
            "    Uninstalling openai-1.54.5:\n",
            "      Successfully uninstalled openai-1.54.5\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DFbMOWIIB6r6"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "openai.api_key  = userdata.get('OpenAI_APIKEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarizing the text as a \"user\" role. The model is \"gpt-4o-mini\"\n",
        "def get_completion_for_gpt_4o_mini(prompt, model=\"gpt-4o-mini\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "Mse-YVfPB9ee"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_for_gpt_4o_mini = f\"\"\"\n",
        "You should express what you want a model to do by \\\n",
        "providing instructions that are as clear and \\\n",
        "specific as you can possibly make them. \\\n",
        "This will guide the model towards the desired output, \\\n",
        "and reduce the chances of receiving irrelevant \\\n",
        "or incorrect responses. Don't confuse writing a \\\n",
        "clear prompt with writing a short prompt. \\\n",
        "In many cases, longer prompts provide more clarity \\\n",
        "and context for the model, which can lead to \\\n",
        "more detailed and relevant outputs.\n",
        "\"\"\"\n",
        "prompt_for_gpt_4o_mini = f\"\"\"\n",
        "Summarize the text delimited by triple backticks \\\n",
        "into a single sentence.\n",
        "```{text_for_gpt_4o_mini}```\n",
        "\"\"\"\n",
        "response_for_gpt_4o_mini = get_completion_for_gpt_4o_mini(prompt_for_gpt_4o_mini )\n",
        "print(response_for_gpt_4o_mini)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMsouR3MEsew",
        "outputId": "00711fdb-9bba-44cd-f2a8-c80a663b09f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To achieve the desired output from a model, provide clear and specific instructions, as longer prompts often enhance clarity and context, leading to more relevant responses.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarizing the text as a \"user\" role. The model is \"gpt-3.5-turbo\"\n",
        "def get_completion_for_gpt_35_turbo(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "n_mDLfpFA6c_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_for_gpt_35_turbo = f\"\"\"\n",
        "You should express what you want a model to do by \\\n",
        "providing instructions that are as clear and \\\n",
        "specific as you can possibly make them. \\\n",
        "This will guide the model towards the desired output, \\\n",
        "and reduce the chances of receiving irrelevant \\\n",
        "or incorrect responses. Don't confuse writing a \\\n",
        "clear prompt with writing a short prompt. \\\n",
        "In many cases, longer prompts provide more clarity \\\n",
        "and context for the model, which can lead to \\\n",
        "more detailed and relevant outputs.\n",
        "\"\"\"\n",
        "prompt_for_gpt_35_turbo = f\"\"\"\n",
        "Summarize the text delimited by triple backticks \\\n",
        "into a single sentence.\n",
        "```{text_for_gpt_35_turbo}```\n",
        "\"\"\"\n",
        "response_for_gpt_35_turbo = get_completion_for_gpt_35_turbo(prompt_for_gpt_35_turbo)\n",
        "print(response_for_gpt_35_turbo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9834c66-3d2f-468e-ad95-5914274e7e2d",
        "id": "JL38odOwBO_U"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is important to provide clear and specific instructions to guide a model towards the desired output and reduce the chances of receiving irrelevant or incorrect responses, even if it means writing a longer prompt for more clarity and context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tactic 2: Ask for a structured output\n",
        "# Asking for generating and responding with an structured output as a \"assistant\" role. The model is \"gpt-3.5-turbo\". The temprature is 0.0\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"assistant\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "OSvCWlm6CSOY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tactic 2: Ask for a structured output in json format\n",
        "prompt = f\"\"\"\n",
        "Generate a list of five made-up software quality fiction book titles along \\\n",
        "with their authors and genres.\n",
        "Provide them in JSON format with the following keys:\n",
        "book_id, title, author, genre.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr-0zqBdE3pa",
        "outputId": "b26c9656-e58e-421c-f273-99f5771de0b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "[\n",
            "    {\n",
            "        \"book_id\": 1,\n",
            "        \"title\": \"The Bug Hunter's Quest\",\n",
            "        \"author\": \"Samantha Code\",\n",
            "        \"genre\": \"Science Fiction\"\n",
            "    },\n",
            "    {\n",
            "        \"book_id\": 2,\n",
            "        \"title\": \"Code of Errors\",\n",
            "        \"author\": \"Max Debug\",\n",
            "        \"genre\": \"Mystery\"\n",
            "    },\n",
            "    {\n",
            "        \"book_id\": 3,\n",
            "        \"title\": \"Quality Assurance Chronicles\",\n",
            "        \"author\": \"Ava Tester\",\n",
            "        \"genre\": \"Fantasy\"\n",
            "    },\n",
            "    {\n",
            "        \"book_id\": 4,\n",
            "        \"title\": \"The Debugging Dilemma\",\n",
            "        \"author\": \"Leo Breakpoint\",\n",
            "        \"genre\": \"Thriller\"\n",
            "    },\n",
            "    {\n",
            "        \"book_id\": 5,\n",
            "        \"title\": \"Software Secrets: A QA Mystery\",\n",
            "        \"author\": \"Ella Codebreak\",\n",
            "        \"genre\": \"Suspense\"\n",
            "    }\n",
            "]\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tactic 2: Ask for a structured output in XML format\n",
        "prompt = f\"\"\"\n",
        "Generate a list of five made-up software quality fiction book titles along \\\n",
        "with their authors and genres.\n",
        "Provide them in XML format with the following tags:\n",
        "book_id, title, author, genre.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp1hf0UvHu_K",
        "outputId": "5cfe3303-f8b3-4225-a991-c548df1b2586"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```xml\n",
            "<book>\n",
            "    <book_id>1</book_id>\n",
            "    <title>The Bug Hunter's Quest</title>\n",
            "    <author>Emily Code</author>\n",
            "    <genre>Science Fiction</genre>\n",
            "</book>\n",
            "<book>\n",
            "    <book_id>2</book_id>\n",
            "    <title>Quality Assurance Chronicles</title>\n",
            "    <author>Sam Test</author>\n",
            "    <genre>Fantasy</genre>\n",
            "</book>\n",
            "<book>\n",
            "    <book_id>3</book_id>\n",
            "    <title>Code of Errors</title>\n",
            "    <author>Ava Debug</author>\n",
            "    <genre>Mystery</genre>\n",
            "</book>\n",
            "<book>\n",
            "    <book_id>4</book_id>\n",
            "    <title>The Testing Prophecy</title>\n",
            "    <author>Max Beta</author>\n",
            "    <genre>Adventure</genre>\n",
            "</book>\n",
            "<book>\n",
            "    <book_id>5</book_id>\n",
            "    <title>Defects in the System</title>\n",
            "    <author>Lily Patch</author>\n",
            "    <genre>Thriller</genre>\n",
            "</book>\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tactic 3: Ask the model to check whether conditions are satisfied\n",
        "# Asking for identify and if successful, generate a step wise instructional text from an input text which doesn't have courtesy words . The model is \"gpt-3.5-turbo\". The temprature is 0.0\n",
        "\n",
        "text_instruction = f\"\"\"\n",
        "Making a cup of tea is easy! First, you need to get some \\\n",
        "water boiling. While that's happening, \\\n",
        "grab a cup and put a tea bag in it. Once the water is \\\n",
        "hot enough, just pour it over the tea bag. \\\n",
        "Let it sit for a bit so the tea can steep. After a \\\n",
        "few minutes, take out the tea bag. If you \\\n",
        "like, you can add some sugar or milk to taste. \\\n",
        "And that's it! You've got yourself a delicious \\\n",
        "cup of tea to enjoy.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, \\\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions, \\\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_instruction}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Completion for Text 1:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYvY9wRHFNJX",
        "outputId": "afe4c261-0da8-482d-9525-c2db2671fb73"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 1:\n",
            "Step 1 - Get some water boiling.\n",
            "Step 2 - Grab a cup and put a tea bag in it.\n",
            "Step 3 - Pour the hot water over the tea bag.\n",
            "Step 4 - Let the tea steep for a few minutes.\n",
            "Step 5 - Remove the tea bag.\n",
            "Step 6 - Add sugar or milk to taste.\n",
            "Step 7 - Enjoy your delicious cup of tea.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tactic 3: Ask the model to check whether conditions are satisfied\n",
        "#Asking for identify and if successful, generate a step wise instructional text from an input text which does have courtesy words . The model is \"gpt-3.5-turbo\". The temprature is 0.0\n",
        "\n",
        "text_instruction_courtesywords = f\"\"\"\n",
        "Making a cup of tea is easy! First, please have some \\\n",
        "water boiling. While that's happening, \\\n",
        "you  should grab a cup and please gently put a tea bag in it. Once the water is \\\n",
        "hot enough, please pour it slowly slowly over the tea bag. \\\n",
        "Please allow it to sit for a bit so the tea can steep. After a \\\n",
        "few minutes, gently pull the tea bag out of the cup. If you \\\n",
        "like, you may want to add some sugar or milk to taste. \\\n",
        "And that's it! if all goes well, you deserve a delicious \\\n",
        "cup of tea to enjoy with family.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, \\\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions, \\\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_instruction_courtesywords}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Completion for Text 1:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "998582f7-bae4-4ff4-9b9e-7c88c42b9342",
        "id": "QNJ_AMxfGBrm"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 1:\n",
            "Step 1 - Have some water boiling.\n",
            "Step 2 - Grab a cup and gently put a tea bag in it.\n",
            "Step 3 - Pour the hot water slowly over the tea bag.\n",
            "Step 4 - Allow the tea to steep for a few minutes.\n",
            "Step 5 - Gently pull the tea bag out of the cup.\n",
            "Step 6 - Add sugar or milk to taste.\n",
            "Step 7 - Enjoy your delicious cup of tea with family.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tactic 3: Ask the model to check whether conditions are satisfied\n",
        "# Asking for identify and if successful, generate a step wise instructional text from an input text which isn't necessarily appears to be an instructional text at all . The model is \"gpt-3.5-turbo\". The temprature is 0.0\n",
        "\n",
        "text_2 = f\"\"\"\n",
        "The sun is shining brightly today, and the birds are \\\n",
        "singing. It's a beautiful day to go for a \\\n",
        "walk in the park. The flowers are blooming, and the \\\n",
        "trees are swaying gently in the breeze. People \\\n",
        "are out and about, enjoying the lovely weather. \\\n",
        "Some are having picnics, while others are playing \\\n",
        "games or simply relaxing on the grass. It's a \\\n",
        "perfect day to spend time outdoors and appreciate the \\\n",
        "beauty of nature.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, \\\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions, \\\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Completion for Text 2:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjvBWeKWmCol",
        "outputId": "0fcd2499-9b8c-4ae6-f6f2-f006d1a592ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 2:\n",
            "No steps provided.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tactic 3: Ask the model to check whether conditions are satisfied\n",
        "# Asking for identify and if successful, generate a step wise instructional text from an input text which appears to be an instructional text at all . The model is \"gpt-3.5-turbo\". The temprature is 0.0\n",
        "\n",
        "text_2 = f\"\"\"\n",
        "The sun is shining brightly today, and the birds are \\\n",
        "singing. It's a beautiful day. First you must go for a \\\n",
        "walk in the park. The flowers are blooming, and the \\\n",
        "trees are swaying gently in the breeze. Then, you should pluck one flower. People \\\n",
        "are out and about, enjoying the lovely weather. Further, You Enjoy the weather. \\\n",
        "Some are having picnics, while others are playing \\\n",
        "games or simply relaxing on the grass. It's a \\\n",
        "perfect day to spend time outdoors and appreciate the \\\n",
        "beauty of nature.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, \\\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions, \\\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Completion for Text 2:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsFcR6NbmF3i",
        "outputId": "3ced4c03-2649-4afd-9f94-d0aad7ebd684"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 2:\n",
            "Step 1 - Go for a walk in the park.\n",
            "Step 2 - Pluck one flower.\n",
            "Step 3 - Enjoy the weather.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tactic 4: \"Few-shot\" prompting\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Your task is to answer in a consistent style without hallucinating.\n",
        "\n",
        ": Teach me about patience.\n",
        "\n",
        ": The river that carves the deepest \\\n",
        "valley flows from a modest spring; the \\\n",
        "grandest symphony originates from a single note; \\\n",
        "the most intricate tapestry begins with a solitary thread.\n",
        "\n",
        ": Teach me about kindness.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfDkt5e4mMyM",
        "outputId": "a9802eb8-5a95-4fbb-dceb-b896cab24577"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kindness is like a gentle breeze that soothes the soul and warms the heart. It is the act of showing compassion, empathy, and understanding towards others without expecting anything in return. Kindness has the power to brighten someone's day, lift their spirits, and create a ripple effect of positivity in the world. It is a simple yet profound gesture that can make a significant difference in someone's life. Practice kindness in your words and actions, and you will not only bring joy to others but also cultivate a sense of fulfillment within yourself.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Principle 2: Give the model time to “think”\n",
        "#Tactic 1: Specify the steps required to complete a task\n",
        "\n",
        "text = f\"\"\"\n",
        "In a charming village, siblings Lorry and Dorry set out on \\\n",
        "a quest to fetch ice from a hilltop \\\n",
        "well. As they climbed, singing joyfully and carefully, misfortune struck \\\n",
        "Dorry tripped on a stone and tumbled \\\n",
        "down the hill, with Lorry following suit. \\\n",
        "Though slightly battered, the pair returned home to \\\n",
        "comforting embraces. Despite the mishap, \\\n",
        "their adventurous spirits remained undimmed, and they \\\n",
        "continued exploring with delight.\n",
        "\"\"\"\n",
        "# example 1\n",
        "prompt_1 = f\"\"\"\n",
        "Perform the following actions:\n",
        "1 - Summarize the following text delimited by triple \\\n",
        "backticks with 1 sentence.\n",
        "2 - Translate the summary into French.\n",
        "3 - List each name in the French summary.\n",
        "4 - Output a json object that contains the following \\\n",
        "keys: french_summary, num_names and names.\n",
        "\n",
        "Separate your answers with line breaks.\n",
        "\n",
        "Text:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt_1)\n",
        "print(\"Completion for prompt 1:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCwtIh-7If89",
        "outputId": "a40f11b9-e390-438f-baba-29a360f4fc43"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for prompt 1:\n",
            "1 - The siblings Lorry and Dorry embark on a quest to fetch ice but encounter misfortune when Dorry falls down a hill, yet they return home with undimmed adventurous spirits.\n",
            "\n",
            "2 - Les frères et sœurs Lorry et Dorry se lancent dans une quête pour chercher de la glace mais rencontrent un malheur lorsque Dorry tombe d'une colline, pourtant ils rentrent chez eux avec des esprits aventureux intacts.\n",
            "\n",
            "3 - Lorry, Dorry\n",
            "\n",
            "4 - \n",
            "{\n",
            "  \"french_summary\": \"Les frères et sœurs Lorry et Dorry se lancent dans une quête pour chercher de la glace mais rencontrent un malheur lorsque Dorry tombe d'une colline, pourtant ils rentrent chez eux avec des esprits aventureux intacts.\",\n",
            "  \"num_names\": 2,\n",
            "  \"names\": [\"Lorry\", \"Dorry\"]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Limitations: Hallucinations: Asked for not to hallucinate\n",
        "prompt = f\"\"\"\n",
        "Tell me about F.A.L.S.E.I.B.L.O.T.S (workload model design) by Sandeep Garg and please do not hallucinate\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0K42OnKnrRW",
        "outputId": "1be62c05-d276-4d25-a75e-fd8e24271c43"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but I couldn't find any information about a book titled \"F.A.L.S.E.I.B.L.O.T.S (workload model design)\" by Sandeep Garg. It's possible that this book doesn't exist or that the title may be incorrect. If you have any other questions or need information on a different topic, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Limitations: Hallucinations\n",
        "prompt = f\"\"\"\n",
        "Tell me about F.A.L.S.E.I.B.L.O.T.S (workload model design) by Sandeep Garg\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhZrcDXiHI6b",
        "outputId": "0dd26a4f-cfe5-403e-8bdd-d092a47e5523"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F.A.L.S.E.I.B.L.O.T.S is a workload model design framework proposed by Sandeep Garg. It stands for Frequency, Arrival rate, Load, Service time, Execution time, Inter-arrival time, Bottleneck, Load, Overhead, Think time, and Scalability. This framework helps in designing workload models for performance evaluation of computer systems. By considering these key factors, the framework aims to provide a comprehensive understanding of the workload characteristics and their impact on system performance. It helps in identifying potential bottlenecks, optimizing system resources, and improving scalability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Limitations: Hallucinations\n",
        "prompt = f\"\"\"\n",
        "Tell me about S.F.D.I.P.O.T by Scott Barber and do not hallucinate\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teT1sfD9oq4W",
        "outputId": "90c80d47-40e6-4fb0-f0f7-7c103f2e069c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S.F.D.I.P.O.T. is an acronym created by Scott Barber that stands for \"Software Failure Distinction, Isolation, Prediction, Observation, and Triage.\" It is a methodology used in software testing and quality assurance to help identify, isolate, predict, observe, and triage software failures. The goal of S.F.D.I.P.O.T. is to improve the efficiency and effectiveness of software testing processes by providing a structured approach to handling software failures. It is not related to hallucinations in any way.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Principle 2: Give the model time to “think”\n",
        "#Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Your task is to determine if the student's solution \\\n",
        "is correct or not.\n",
        "To solve the problem do the following:\n",
        "- First, work out your own solution to the problem.\n",
        "- Then compare your solution to the student's solution \\\n",
        "and evaluate if the student's solution is correct or not.\n",
        "Don't decide if the student's solution is correct until\n",
        "you have done the problem yourself.\n",
        "\n",
        "Use the following format:\n",
        "Question:\n",
        "```\n",
        "question here\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "student's solution here\n",
        "```\n",
        "Actual solution:\n",
        "```\n",
        "steps to work out the solution and your solution here\n",
        "```\n",
        "Is the student's solution the same as actual solution \\\n",
        "just calculated:\n",
        "```\n",
        "yes or no\n",
        "```\n",
        "Student grade:\n",
        "```\n",
        "correct or incorrect\n",
        "```\n",
        "\n",
        "Question:\n",
        "```\n",
        "I'm building a solar power installation and I need help \\\n",
        "working out the financials.\n",
        "- Land costs\n",
        "100 / square foot and I can buy solar panels for 250 /  square foot\n",
        "- I negotiated a contract for maintenance that will cost \\\n",
        "me a flat  100k per year and an additional\n",
        "10 / square \\\n",
        "foot\n",
        "What is the total cost for the first year of operations \\\n",
        "as a function of the number of square feet.\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "```\n",
        "Actual solution:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qbJm9MbrL79",
        "outputId": "acc2a653-2262-4b06-8c8c-c279ba7b2c5f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The student's solution is almost correct, but there is a small mistake in calculating the total cost.\n",
            "\n",
            "Actual solution:\n",
            "Total cost = Land cost + Solar panel cost + Maintenance cost\n",
            "Total cost = 100x + 250x + 100,000 + 10x\n",
            "Total cost = 360x + 100,000\n",
            "\n",
            "Is the student's solution the same as the actual solution just calculated:\n",
            "No\n",
            "\n",
            "Student grade:\n",
            "```\n",
            "incorrect\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Principle 2: Give the model time to “think”\n",
        "#Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Your task is to determine if the student's solution \\\n",
        "is correct or not.\n",
        "To solve the problem do the following:\n",
        "- First, work out your own solution to the problem.\n",
        "- Then compare your solution to the student's solution \\\n",
        "and evaluate if the student's solution is correct or not.\n",
        "Don't decide if the student's solution is correct until\n",
        "you have done the problem yourself.\n",
        "\n",
        "Use the following format:\n",
        "Question:\n",
        "```\n",
        "question here\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "student's solution here\n",
        "```\n",
        "Actual solution:\n",
        "```\n",
        "steps to work out the solution and your solution here\n",
        "```\n",
        "Is the student's solution the same as actual solution \\\n",
        "just calculated:\n",
        "```\n",
        "yes or no\n",
        "```\n",
        "Student grade:\n",
        "```\n",
        "correct or incorrect\n",
        "```\n",
        "\n",
        "Question:\n",
        "```\n",
        "I'm building a solar power installation and I need help \\\n",
        "working out the financials.\n",
        "- Land costs\n",
        "250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost \\\n",
        "me a flat\n",
        "10 / square \\\n",
        "foot\n",
        "What is the total cost for the first year of operations \\\n",
        "as a function of the number of square feet.\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "```\n",
        "Actual solution:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChJ1ofpzpWP-",
        "outputId": "d539ce3e-9e99-49e3-d995-54cbe297cad7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The student's solution is incorrect.\n",
            "\n",
            "Actual solution:\n",
            "Let x be the size of the installation in square feet.\n",
            "Costs:\n",
            "1. Land cost: 250x\n",
            "2. Maintenance cost: 10x\n",
            "Total cost: 250x + 10x = 260x\n",
            "\n",
            "Is the student's solution the same as the actual solution just calculated:\n",
            "No\n",
            "\n",
            "Student grade:\n",
            "Incorrect\n"
          ]
        }
      ]
    }
  ]
}