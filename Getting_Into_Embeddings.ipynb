{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCaVHDR5j30Fmit2TkPttg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/testanalyst/AILaunchpad/blob/main/Getting_Into_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pAjGSbA-1sw",
        "outputId": "ef72aaaa-fc52-46e6-de72-3ea3b211c2da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "[ 1.36956107e-02  2.34063459e-03  6.29611537e-02  6.82101771e-02\n",
            " -4.33892161e-02  9.19681136e-03 -1.69118252e-02 -1.34128153e-01\n",
            "  3.21926549e-02  1.26125753e-01 -8.24652798e-03 -4.54372820e-03\n",
            "  3.86945941e-02  1.65337455e-02 -8.53307545e-02  8.93690288e-02\n",
            "  9.67764333e-02  4.94113490e-02 -1.90904411e-03 -2.01585554e-02\n",
            " -3.22265625e-02  3.63498256e-02  5.62337227e-02 -1.60386832e-03\n",
            "  4.38537598e-02 -7.64702708e-02 -9.97297466e-02  2.08062064e-02\n",
            "  9.28005651e-02 -1.00341797e-01  7.27640763e-02 -3.82351354e-02\n",
            " -3.46272774e-02  9.35829990e-03 -9.09665450e-02 -7.01226108e-03\n",
            " -6.70030387e-03  3.77061628e-02 -3.81910540e-02  7.80707449e-02\n",
            "  5.42144775e-02 -8.20583776e-02  7.90608749e-02  4.54033725e-03\n",
            " -5.82139753e-02  1.56690814e-02 -2.14640293e-02  2.82864049e-02\n",
            "  1.94769967e-02  6.22558594e-03  2.57161465e-02  5.01725934e-02\n",
            "  8.94300640e-02  2.25423183e-02 -7.37304688e-02  9.10305455e-02\n",
            " -1.30588114e-01 -2.83135311e-03 -9.81987827e-03 -7.40152970e-02\n",
            " -5.61794713e-02  3.45187727e-03  2.15115026e-02 -1.07069224e-01\n",
            "  1.86140276e-02 -1.30547415e-02 -4.73497175e-02  7.71891251e-02\n",
            " -1.22477217e-02  9.41026509e-02  5.74679896e-02 -2.01856829e-02\n",
            "  9.13492814e-02  7.39203580e-03 -1.59152567e-01  2.31323242e-02\n",
            "  5.93126081e-02 -2.10232195e-03  1.30940750e-01  6.75659180e-02\n",
            "  2.79066302e-02 -1.47026911e-01  1.33721247e-01  9.03513134e-02\n",
            " -9.60540771e-02  3.82834524e-02 -1.06323242e-01  8.12445730e-02\n",
            "  3.79774310e-02  3.26402448e-02 -2.99750436e-02  6.95944875e-02\n",
            " -4.77600098e-02 -1.10588923e-01 -1.02077909e-01 -2.44750977e-02\n",
            "  9.08745676e-02  3.66075300e-02  6.80881068e-02  7.56496862e-02\n",
            " -6.14827462e-02 -9.23224539e-02  1.71169713e-02 -2.70453561e-02\n",
            "  5.11559397e-02 -6.35308176e-02 -1.09456377e-02 -3.51698138e-02\n",
            "  4.58713099e-02 -1.59722224e-01 -1.38780385e-01 -2.03450527e-02\n",
            " -1.99178066e-02 -2.20404733e-02  5.63286692e-02  1.55951604e-01\n",
            "  9.30362288e-03  4.87772636e-02  7.08669052e-02  5.89735247e-02\n",
            " -1.19710289e-01 -3.46815325e-02 -7.24690780e-02  9.81445312e-02\n",
            " -5.69661439e-04 -5.23342565e-02 -5.79746030e-02  1.94227435e-02\n",
            "  4.67800573e-02  5.93939871e-02 -1.24538846e-01 -1.40516490e-01\n",
            "  4.48269323e-02 -8.35503452e-03 -2.86831334e-02 -1.34060323e-01\n",
            " -7.10991770e-02 -2.70317923e-02 -1.12711592e-02  1.53476298e-01\n",
            "  1.76357701e-02 -7.40941381e-03  9.18579102e-03 -5.78070730e-02\n",
            " -3.18603516e-02 -2.72725429e-02 -4.97775599e-02 -4.08799909e-02\n",
            " -5.21918386e-02 -5.09779193e-02  1.22029625e-01  4.95622419e-02\n",
            " -4.55729151e-03  8.37402344e-02 -6.62129745e-02  4.21244316e-02\n",
            " -5.49045131e-02 -5.18832728e-02 -3.44433263e-02  4.23787422e-02\n",
            "  5.05235465e-03  3.40983085e-02  9.05939713e-02  6.84407577e-02\n",
            " -3.32302526e-02 -2.97241211e-02  8.16650391e-02  1.15288631e-03\n",
            "  1.76323781e-04 -4.18158621e-02 -1.85329854e-01 -7.98882358e-03\n",
            " -1.94905605e-02 -9.41568986e-02 -1.26898870e-01 -4.51660156e-03\n",
            "  1.81274414e-02 -2.83542201e-02 -3.98763036e-03  1.85479061e-03\n",
            " -1.11524791e-01 -1.52197946e-02 -3.26843262e-02  3.94422747e-02\n",
            " -4.72208671e-02 -4.99471044e-03 -2.52592303e-02  1.45209417e-01\n",
            "  1.05445012e-01  1.91243493e-03 -4.38232422e-02  4.82177734e-02\n",
            "  1.93481445e-02  5.10389544e-02 -1.24254018e-01  7.73145854e-02\n",
            " -1.04492188e-01  2.63943151e-02 -4.23177099e-03 -1.29177511e-01\n",
            " -1.13037109e-01  5.58810774e-03 -3.24842660e-03  8.69411901e-02\n",
            "  3.47832590e-02  9.00336355e-02 -3.04904506e-02  1.07855901e-01\n",
            "  2.31662318e-02  8.97555891e-03  7.09364144e-03  5.34125417e-02\n",
            " -5.38465716e-02  5.72306328e-02 -7.85183385e-02  7.25775808e-02\n",
            "  2.66520176e-02  2.97376839e-03 -1.32242844e-01  3.60107422e-02\n",
            " -7.04888254e-02  2.72216797e-02  6.05990104e-02 -5.82885742e-02\n",
            "  3.29861119e-02 -9.28005651e-02 -7.35812709e-02  9.03591588e-02\n",
            "  7.03938818e-03 -5.11338972e-02  1.46091044e-01 -1.59491643e-01\n",
            "  5.97127266e-02 -5.14695905e-02 -3.73399518e-02  1.27699114e-02\n",
            " -2.62993705e-02 -5.22867851e-02 -4.59662527e-02  2.76963972e-02\n",
            " -2.38308385e-02 -1.87344030e-02  7.01565221e-02 -1.17241755e-01\n",
            "  1.71644427e-02 -4.52100970e-02 -1.00233294e-02  3.07888463e-02\n",
            "  7.26453960e-02  1.06065534e-02  1.45941842e-02 -5.80647774e-02\n",
            "  2.18370222e-02  1.09993830e-01 -1.29123265e-02 -3.64447683e-02\n",
            "  2.45361328e-02 -3.96457240e-02 -4.64816615e-02 -4.37554270e-02\n",
            " -2.10639108e-02 -3.40847448e-02 -1.62353516e-02 -3.43560129e-02\n",
            "  6.69216588e-02  2.04074442e-01 -4.16259766e-02 -1.94837786e-02\n",
            " -9.08203125e-02 -2.17285156e-02 -5.07812500e-02  2.18302403e-02\n",
            "  3.71771902e-02 -4.31179479e-02 -1.26885306e-02 -1.33124456e-01\n",
            " -1.72254769e-03 -1.29014760e-01  3.14873606e-02 -7.80436173e-02\n",
            "  3.56140137e-02 -9.29904506e-02 -1.99517142e-02  1.13637291e-01\n",
            "  3.58886719e-02  9.20342356e-02 -9.83284861e-02  1.21527780e-02\n",
            " -8.65783691e-02  5.58810756e-02 -1.68551981e-01  7.47545063e-02\n",
            " -1.51910573e-01  3.87912337e-03 -4.96690534e-02 -1.63845494e-02\n",
            " -4.61459681e-02 -3.17179374e-02  4.87467460e-02 -9.93652344e-02]\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Load pre-trained Word2Vec model\n",
        "word2vec_model = api.load('word2vec-google-news-300')\n",
        "\n",
        "# Example function to get embeddings for a sentence\n",
        "def get_sentence_embedding(sentence):\n",
        "    words = sentence.split()\n",
        "    word_vectors = [word2vec_model[word] for word in words if word in word2vec_model]\n",
        "    return sum(word_vectors) / len(word_vectors)\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"My bank is 2 miles away from my office\"\n",
        "embedding = get_sentence_embedding(sentence)\n",
        "print(embedding)\n",
        "\n",
        "# Instead of sentence embedding get word embedding for the word 'Bank'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dimensionality = len(embedding)\n",
        "print(f\"Dimensionality of the embedding: {dimensionality}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzML7hUFCSzJ",
        "outputId": "c3ba58ee-d9d1-499a-8873-c6b7c0d531bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensionality of the embedding: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-jcrJG9CW4f",
        "outputId": "35c7f7d9-2757-4739-c37b-97d10a32fd79"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to get embeddings for a sentence using BERT\n",
        "def get_sentence_embedding(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # Take the mean of the last hidden state across all tokens for the sentence embedding\n",
        "    sentence_embedding = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
        "    return sentence_embedding\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"My bank is 2 miles away from my office\"\n",
        "embedding_BERT = get_sentence_embedding(sentence)\n",
        "print(embedding_BERT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC5kidZLCbRS",
        "outputId": "a877daa1-b5ca-4bdb-e768-31823fd7bd30"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 7.5392e-03,  1.2506e-01,  1.4103e-01, -3.4694e-02,  2.7930e-01,\n",
            "         8.0504e-02,  2.0659e-01,  5.0561e-01,  3.0793e-01, -2.2332e-01,\n",
            "         2.6898e-01, -3.2897e-01, -1.3582e-02,  3.4275e-01, -1.4591e-01,\n",
            "         1.1451e-01,  1.3383e-01,  9.2703e-02, -1.2177e-01,  3.1151e-01,\n",
            "        -1.3779e-01, -2.0864e-01,  9.8295e-02,  4.8174e-01,  1.6992e-01,\n",
            "         1.8185e-01, -1.9642e-01,  1.3874e-01, -2.8608e-01, -1.8854e-01,\n",
            "         1.6423e-01, -1.6490e-01,  6.7301e-02, -7.1841e-02,  3.9710e-01,\n",
            "        -4.5112e-01,  1.2719e-01,  9.4895e-02, -4.8089e-01,  4.7171e-01,\n",
            "        -4.6157e-01, -1.4512e-01, -7.6379e-02,  6.9886e-02, -2.2302e-01,\n",
            "        -3.5039e-01,  1.6231e-01, -3.3414e-01, -1.1659e-01, -1.6587e-01,\n",
            "        -3.1789e-01,  2.4395e-01, -3.4452e-01,  1.2679e-01,  2.9435e-01,\n",
            "         7.6291e-01, -7.2761e-02, -4.8699e-01, -2.8132e-01, -1.2864e-01,\n",
            "         5.9352e-01, -1.4877e-01, -2.3235e-02, -3.2729e-01,  3.8141e-02,\n",
            "         8.8554e-02,  3.3424e-01,  2.0919e-01, -4.7514e-01,  1.0004e-01,\n",
            "         7.0567e-02,  5.3912e-02,  2.4089e-01, -4.3510e-02, -1.3431e-01,\n",
            "         1.3028e-01,  1.4489e-02,  3.4937e-01,  2.1711e-01,  1.5436e-01,\n",
            "        -1.0129e-01,  1.7633e-01, -1.5732e-01,  1.1927e-01,  3.5796e-01,\n",
            "         2.0654e-01, -1.4048e-01, -7.0689e-02,  3.7261e-02,  2.1105e-01,\n",
            "         1.4084e-01,  2.8850e-01, -2.8803e-01,  3.1638e-01,  9.2631e-02,\n",
            "        -2.8626e-01, -7.9812e-02,  6.4655e-02, -1.8216e-01,  4.0940e-01,\n",
            "        -6.1564e-02, -5.5662e-01,  1.1628e-03,  3.3611e-01,  2.5661e-01,\n",
            "        -2.2780e-02,  1.8317e-01,  1.0148e-01,  5.1807e-01, -1.8501e-01,\n",
            "        -7.9311e-02, -2.5184e-01,  2.3359e-01, -3.2714e-01, -2.8742e-01,\n",
            "         3.9022e-01,  5.0911e-01, -2.4063e-01, -5.5736e-02, -1.9229e-01,\n",
            "        -2.1282e-01,  2.5849e-01, -3.9639e-02,  8.5161e-01, -2.2780e-03,\n",
            "        -4.0455e-02, -2.1162e-01,  2.6291e-01, -8.8048e-02, -7.3447e-01,\n",
            "        -2.6789e-01,  2.7382e-01,  4.9462e-01, -2.6641e-02,  3.6114e-01,\n",
            "        -3.5590e-03, -7.6621e-02,  1.1633e-01,  2.7135e-02,  1.4439e-01,\n",
            "         3.4668e-01,  3.5585e-01, -1.7265e-01,  2.7930e-01,  2.4253e-01,\n",
            "        -1.0722e-01, -2.4373e-02, -2.3484e-01,  2.3104e-01, -1.5766e-02,\n",
            "         9.5229e-02,  3.3384e-01, -3.5138e-01,  1.3948e-01, -4.5299e-01,\n",
            "        -1.7550e-01, -1.9439e-01,  1.9199e-01,  7.4670e-02,  2.3277e-01,\n",
            "         1.6984e-01, -1.7666e-01, -1.4542e-01,  8.7474e-02, -4.8136e-01,\n",
            "        -1.6010e-01,  5.8661e-02,  4.7990e-01,  1.2137e-02,  1.8784e-01,\n",
            "        -5.1947e-01, -4.5207e-01,  2.7835e-01, -7.6889e-02,  2.1106e-01,\n",
            "        -3.5587e-02, -1.6454e-02, -1.2140e-01,  1.9651e-01,  8.3234e-02,\n",
            "        -1.0752e+00,  7.4495e-02,  5.8096e-02,  3.1755e-02,  6.8892e-02,\n",
            "        -4.8506e-01,  2.7897e-01, -1.8192e-01,  1.3168e-01, -9.7322e-02,\n",
            "        -3.4345e-01, -5.9250e-01,  1.4019e-01,  4.9465e-02,  1.3530e-01,\n",
            "        -2.3929e-01, -2.5400e-01, -7.6068e-01, -3.8431e-02,  1.1372e-01,\n",
            "         7.8337e-03, -2.7176e-01,  4.8894e-02, -9.9891e-02, -1.3206e-01,\n",
            "         6.0372e-01,  6.5726e-02, -3.2959e-01,  2.3937e-01,  1.8400e-01,\n",
            "        -2.4144e-01,  2.8961e-01,  2.1242e-01, -6.3130e-02, -1.3828e-01,\n",
            "        -8.3649e-02,  2.5700e-01, -1.9959e-01,  2.7184e-01,  6.4427e-02,\n",
            "         1.4552e-01,  1.0910e-01, -1.7625e-01,  4.9269e-01, -2.1369e-01,\n",
            "         1.3918e-01,  4.4821e-02, -1.5895e-01, -1.2649e-01,  8.7883e-01,\n",
            "         3.9984e-02, -6.0637e-01,  2.0151e-01, -2.7588e-01, -6.2093e-01,\n",
            "        -4.4534e-02, -3.1965e-01, -3.2558e-01,  1.5448e-01, -6.3784e-02,\n",
            "        -4.2660e-01,  8.9818e-02,  3.5683e-01,  1.7987e-01,  1.2177e-01,\n",
            "         1.3290e-01,  1.1738e-01, -2.6184e-01, -2.8945e-02, -1.0623e-01,\n",
            "        -4.2728e-01, -6.3356e-01,  2.5655e-01, -4.6279e-01,  2.4755e-01,\n",
            "         5.8232e-02, -2.0762e-01,  3.3459e-01, -5.7235e-02,  1.3427e-01,\n",
            "        -4.6907e-02,  2.1342e-01,  4.8634e-01,  1.8967e-01, -3.2711e-01,\n",
            "        -1.8025e-01,  3.1841e-01,  3.1317e-01,  2.6762e-01, -1.1856e-01,\n",
            "         1.2001e-01, -3.0025e-01, -1.4548e-02, -2.4940e-02,  1.0928e-01,\n",
            "        -1.1742e-01,  3.5103e-01,  2.2347e-01, -1.9604e-01, -6.1885e-04,\n",
            "         7.4545e-01,  4.0426e-01,  1.3586e-02,  8.2333e-02,  2.3990e-01,\n",
            "        -2.5379e-01,  4.3990e-02, -3.5806e-01, -8.2779e-02, -1.1066e-01,\n",
            "        -3.0018e-01,  3.4416e-01, -1.5569e-01, -1.2343e-01,  3.8293e-01,\n",
            "         1.5231e-01,  2.8693e-01,  5.9771e-02,  5.0001e-01, -5.0600e-01,\n",
            "        -9.6353e-02, -7.5037e-02,  6.2192e-02, -2.5256e-01, -3.3481e-01,\n",
            "        -7.4429e-02, -8.5213e-02, -4.3022e-01, -4.1057e+00,  1.9090e-01,\n",
            "        -3.0248e-01, -8.2207e-02,  3.5581e-01, -7.1710e-02,  7.2879e-02,\n",
            "        -3.2306e-01, -2.9771e-01, -2.0132e-01, -2.0323e-01,  1.9573e-02,\n",
            "         6.3565e-01, -2.0518e-01, -1.9439e-01, -7.1850e-02,  1.0526e-01,\n",
            "        -5.1152e-01, -2.0564e-01,  1.9048e-01, -1.2783e-02,  1.4104e-01,\n",
            "         2.2958e-01, -1.5024e-01,  5.6537e-01,  1.0263e+00, -1.8726e-01,\n",
            "         3.9440e-01, -2.3125e-02, -1.1824e-01, -6.6435e-02, -2.2611e-01,\n",
            "         2.2711e-02,  4.2577e-02,  3.3648e-01, -7.0146e-02, -1.9083e-02,\n",
            "        -1.8320e-01,  1.0303e-01, -4.5009e-02,  3.1686e-01, -2.2884e-01,\n",
            "         3.9836e-01,  1.4662e-02,  5.8126e-01, -2.3995e-01, -5.7453e-02,\n",
            "         6.3296e-02,  3.6581e-02,  8.8532e-02,  1.4281e-01,  1.6062e-01,\n",
            "         5.6052e-02, -1.6864e-01, -6.8990e-03, -4.2218e-01,  3.9074e-01,\n",
            "         5.3810e-01, -1.0142e-01, -9.0192e-02,  1.9558e-01, -4.6573e-01,\n",
            "        -3.7909e-01, -1.2120e-01,  9.9392e-02, -1.9904e-01, -4.7815e-01,\n",
            "        -9.2140e-02, -5.5165e-02,  1.8201e-01, -2.9922e-02, -1.4556e-02,\n",
            "        -2.8928e-01, -8.4921e-01, -1.2720e-01,  4.7203e-02, -2.7056e-01,\n",
            "         9.6377e-02,  3.4409e-01,  1.7640e-03, -1.2436e-01,  1.9617e-01,\n",
            "        -4.4299e-02,  1.6719e-01,  4.4454e-02, -5.9972e-01, -1.1474e-01,\n",
            "         4.1220e-01,  7.6429e-02, -1.3861e-01,  1.0634e-02,  4.8172e-01,\n",
            "         4.3696e-01,  8.9921e-02,  1.3135e-01,  2.7810e-02,  3.4306e-02,\n",
            "        -5.6449e-01,  6.9951e-02,  2.0785e-02,  1.4107e-01,  3.2047e-01,\n",
            "        -1.1963e-01, -1.3606e-01,  2.2350e-01, -1.0719e-01, -7.5031e-02,\n",
            "         4.1627e-01, -3.6811e-01,  5.4286e-02,  4.5418e-02, -6.0475e-01,\n",
            "         5.9046e-01, -1.7085e-01, -1.7156e-01, -2.1226e-01,  1.3474e-01,\n",
            "         1.9180e-01, -3.5250e-01, -7.1959e-02, -4.9690e-02,  3.1011e-01,\n",
            "        -1.9053e-01, -5.8481e-01, -5.1282e-01, -8.5408e-02,  1.9596e-02,\n",
            "        -3.9162e-01,  8.4008e-02,  1.4796e-01,  1.4379e-01, -3.8760e-02,\n",
            "        -2.6230e-01,  2.4224e-01,  5.9944e-02,  2.2907e-02, -1.1658e-01,\n",
            "        -3.0719e-01,  2.1860e-01,  1.5669e-01, -3.1631e-02,  2.4772e-01,\n",
            "        -2.5613e-02,  3.7808e-01, -2.2671e-01,  4.3218e-01, -7.7120e-02,\n",
            "        -1.8746e-01, -1.7116e-01, -8.1307e-02, -3.0685e-01, -5.6673e-01,\n",
            "         1.9860e-02, -1.5111e-01, -1.4065e-01,  1.2595e-01,  4.7287e-01,\n",
            "        -9.3223e-02, -5.6326e-01, -8.0991e-02,  5.4130e-02, -1.1240e-01,\n",
            "         3.1233e-01,  2.6253e-01, -4.3948e-01,  4.1581e-02,  1.0453e-01,\n",
            "        -5.6763e-02, -3.4826e-03,  2.0372e-01, -1.1160e-01, -5.5572e-02,\n",
            "        -2.7978e-02, -8.8186e-02,  1.1950e-01,  1.5999e-01,  2.6800e-01,\n",
            "        -2.4630e-01,  4.6475e-02, -8.8423e-02, -5.8690e-02, -2.0863e-01,\n",
            "        -6.4582e-02, -3.5411e-01,  3.9831e-01,  1.6809e-01,  8.1492e-02,\n",
            "        -1.8663e-01,  3.5202e-01,  2.1907e-01, -4.3618e-01,  3.3859e-01,\n",
            "        -2.8050e-01, -4.0920e-01, -1.3903e-01, -2.6624e-01,  6.2349e-01,\n",
            "         1.4597e-01,  1.7392e-01,  3.1630e-01,  1.0743e-01,  3.1895e-01,\n",
            "        -2.3504e-01,  4.4711e-03, -3.4746e-01, -7.9059e-02,  2.9452e-01,\n",
            "         2.9201e-01, -3.0980e-01,  2.3424e-01, -3.2009e-01,  1.5871e-01,\n",
            "        -4.0583e-01, -3.8150e-01, -3.0090e-01,  1.6657e-01,  1.3294e-01,\n",
            "        -2.0642e-01, -1.5341e-01,  9.7514e-03, -2.7438e-01, -4.1637e-01,\n",
            "         8.5057e-02,  8.2754e-02, -3.8690e-01, -1.1727e-01,  1.8146e-01,\n",
            "        -1.7973e-01, -1.9553e-01, -2.4981e-01, -1.5225e-01, -2.9047e-01,\n",
            "         1.9156e-01, -2.2118e-01,  3.6973e-01,  2.3513e-01, -2.4609e-01,\n",
            "         9.5576e-02,  1.4601e-01,  3.2849e-01, -2.3305e-01, -1.6992e-01,\n",
            "         5.8631e-02, -3.3215e-01,  9.4095e-02, -1.8407e-01,  6.0136e-02,\n",
            "         2.9812e-01,  1.7807e-02,  5.5181e-01,  5.5973e-02,  3.1093e-02,\n",
            "         1.6782e-01,  2.0004e-01, -2.3527e-02, -7.5152e-01, -4.3595e-01,\n",
            "         1.9614e-01,  2.3792e-01, -6.0946e-02, -2.0272e-01, -1.5350e-01,\n",
            "        -2.1681e-02,  1.4925e-01,  4.7421e-04,  1.6026e-01,  2.8458e-02,\n",
            "        -2.7206e-02,  2.3651e-01, -3.1993e-01, -1.6831e-01, -1.3650e-02,\n",
            "         1.8871e-01, -1.8974e-01, -6.4522e-01, -7.3844e-02, -4.5176e-01,\n",
            "        -3.0795e-01, -2.9188e-01, -1.3219e-01,  1.1527e-01,  2.7034e-01,\n",
            "        -5.7079e-02, -5.4996e-01,  2.3402e-01,  8.8477e-02, -3.1749e-02,\n",
            "         1.4928e-01, -1.8313e-01, -1.5354e-03,  2.4812e-01,  2.4299e-01,\n",
            "         8.2349e-02, -8.2008e-02, -3.3886e-01,  1.1690e-01,  6.3283e-01,\n",
            "        -7.0586e-03, -1.4852e-01, -1.8040e-02, -2.6164e-01, -6.5242e-02,\n",
            "        -3.9550e-02,  3.0206e-01, -3.3380e-01,  1.1896e-01, -1.2062e-01,\n",
            "        -4.4047e-01, -5.2164e-02,  1.4258e-02, -4.4621e-01, -4.9326e-01,\n",
            "         5.0536e-01,  6.5781e-01, -3.0696e-01, -4.8285e-01, -2.2542e-01,\n",
            "        -3.0497e-01, -5.0984e-01,  1.3994e-01, -2.3423e-03, -3.7601e-01,\n",
            "         3.8860e-01,  9.0392e-02,  1.3385e-01,  3.9740e-01, -2.0127e-01,\n",
            "         9.0999e-02,  4.7171e-02, -8.0048e-02, -3.4500e-01,  1.8230e-01,\n",
            "        -3.5095e-01,  7.0473e-01,  1.3018e-01,  2.3525e-02, -2.6533e-01,\n",
            "         4.8218e-02,  1.2159e-01, -1.5799e-01,  4.2725e-02, -1.4701e-01,\n",
            "        -1.9431e-01,  6.0659e-01,  3.8553e-01, -1.2879e-01,  5.3944e-01,\n",
            "        -1.1721e-01,  4.0780e-01,  3.5412e-01,  2.7724e-02,  2.3589e-01,\n",
            "        -2.2562e-01, -3.0011e-01,  1.2540e-01,  4.4085e-01,  1.8341e-01,\n",
            "         1.7152e-01,  2.6891e-01,  1.5626e-01,  1.5819e-01, -8.0996e-03,\n",
            "        -1.2267e-01, -3.0669e-01, -3.8628e-01,  2.3505e-01,  2.2738e-01,\n",
            "        -5.7403e-01, -2.9143e-01,  2.6481e-01, -1.5664e-01,  6.5897e-02,\n",
            "        -2.3737e-01,  1.5840e-02, -1.3488e-01,  3.4126e-01, -2.7002e-01,\n",
            "        -9.7761e-02, -1.2261e-02, -5.2099e-02,  2.0752e-01,  9.3768e-02,\n",
            "        -3.9280e-01, -3.9388e-01,  2.6080e-01, -2.2197e-01, -1.3204e-01,\n",
            "        -3.7481e-01, -9.9407e-02, -5.7384e-01,  2.5154e-01, -1.3393e-01,\n",
            "        -1.8337e-01, -3.7449e-01,  5.6192e-01, -1.8540e-01,  2.1073e-01,\n",
            "        -3.3281e-01,  4.7344e-01,  2.3545e-01,  4.8243e-01, -1.4170e-01,\n",
            "        -3.9785e-01,  3.0640e-01,  6.4555e-03,  1.6929e-01,  1.4536e-01,\n",
            "         2.1964e-02,  1.0923e-02, -3.4941e-01,  1.4645e-01,  5.9338e-01,\n",
            "        -7.0954e-01,  1.7898e-01,  2.1030e-01,  4.5913e-01,  3.2708e-01,\n",
            "         2.3794e-01, -2.4734e-01, -2.4293e-02, -1.7228e-02, -3.6971e-03,\n",
            "         7.9219e-02,  4.2431e-01, -9.7366e-02, -1.8824e-01,  1.3237e-01,\n",
            "        -4.1856e-02, -4.0294e-02, -9.9180e-02, -4.7529e-02,  1.6311e-01,\n",
            "         2.8387e-01,  1.8606e-01, -2.3000e-01, -2.0089e-02,  1.5475e-01,\n",
            "         4.9267e-02, -1.5929e-02, -2.2707e-01,  1.3302e-01,  2.8528e-01,\n",
            "        -4.1214e-02, -1.6512e-01, -6.9759e-01,  1.0862e-01, -2.5980e-02,\n",
            "        -9.0896e-01, -2.7740e-01, -5.4647e-01,  3.7183e-01, -1.9360e-01,\n",
            "         3.3588e-03, -5.3955e-01,  6.8757e-02,  1.0573e-01, -3.6772e-02,\n",
            "        -4.3318e-01,  2.3244e-01,  1.7756e-01])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dimensionality = len(embedding_BERT)\n",
        "print(f\"Dimensionality of the embedding from BERT: {dimensionality}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDwSA_WoC2Fj",
        "outputId": "3f36ce18-81e8-40e4-fde4-4ec7a4d15ed6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensionality of the embedding from BERT: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Function to get embeddings for a sentence using BERT\n",
        "def get_sentence_embedding_BERT(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # Take the mean of the last hidden state across all tokens for the sentence embedding\n",
        "    sentence_embedding_BERT = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
        "    return sentence_embedding_BERT.numpy()\n",
        "\n",
        "# Example sentences\n",
        "sentence1 = \"My bank is 2 miles away from my office\"\n",
        "sentence2 = \"The financial institution is located near my workplace\"\n",
        "\n",
        "# Get embeddings for the sentences\n",
        "embedding_BERT1 = get_sentence_embedding_BERT(sentence1)\n",
        "embedding_BERT2 = get_sentence_embedding_BERT(sentence2)\n",
        "\n",
        "# Calculate cosine similarity\n",
        "similarity = cosine_similarity([embedding_BERT1], [embedding_BERT2])[0][0]\n",
        "print(f\"Cosine Similarity between the two sentences: {similarity}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXPO9c0WDvqj",
        "outputId": "16cb5503-cee5-4731-f0b8-2b587fbe07b3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity between the two sentences: 0.7859391570091248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Function to get embeddings for a sentence using BERT\n",
        "def get_sentence_embedding_BERT(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # Take the mean of the last hidden state across all tokens for the sentence embedding\n",
        "    sentence_embedding_BERT = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
        "    return sentence_embedding_BERT.numpy()\n",
        "\n",
        "# Example sentences\n",
        "sentence1 = \"My bank is 2 miles away from my office\"\n",
        "sentence2 = \"The ganga river's bank is located near my home\"\n",
        "\n",
        "# Get embeddings for the sentences\n",
        "embedding_BERT1 = get_sentence_embedding_BERT(sentence1)\n",
        "embedding_BERT2 = get_sentence_embedding_BERT(sentence2)\n",
        "\n",
        "# Calculate cosine similarity\n",
        "similarity = cosine_similarity([embedding_BERT1], [embedding_BERT2])[0][0]\n",
        "print(f\"Cosine Similarity between the two sentences: {similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QW3eT08En_N",
        "outputId": "937adc5f-7d22-4752-e811-b70c39dc9d06"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity between the two sentences: 0.7335179448127747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "25X30takGC6Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}